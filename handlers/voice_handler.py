from aiogram import Router, F
from aiogram.types import Message, CallbackQuery
from aiogram.filters import Command, StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from utils.openai_client import OpenAIClient
from keyboards.inline import get_end_keyboard
from config import IMAGE_PATHS
import logging
import aiofiles
import io

router = Router()
logger = logging.getLogger(__name__)
openai_client = OpenAIClient()


class VoiceStates(StatesGroup):
    waiting_for_voice = State()


@router.message(Command("voice"))
@router.callback_query(F.data == "voice")
async def start_voice_chat(update: Message | CallbackQuery, state: FSMContext):
    try:
        if isinstance(update, CallbackQuery):
            message = update.message
            await update.answer()
        else:
            message = update

        caption = "üé§ –ì–æ–ª–æ—Å–æ–≤–æ–π —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω! –û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ —Ç–µ–∫—Å—Ç."

        try:
            async with aiofiles.open(IMAGE_PATHS['voice'], 'rb') as photo:
                if isinstance(update, CallbackQuery):
                    await message.edit_media(
                        media=InputMediaPhoto(media=photo, caption=caption),
                        reply_markup=get_end_keyboard()
                    )
                else:
                    await message.answer_photo(
                        photo=photo,
                        caption=caption,
                        reply_markup=get_end_keyboard()
                    )
        except:
            if isinstance(update, CallbackQuery):
                await message.edit_text(
                    caption,
                    reply_markup=get_end_keyboard()
                )
            else:
                await message.answer(
                    caption,
                    reply_markup=get_end_keyboard()
                )

        await state.set_state(VoiceStates.waiting_for_voice)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ start_voice_chat: {e}")


@router.message(VoiceStates.waiting_for_voice, F.voice)
async def handle_voice_message(message: Message, state: FSMContext):
    voice = message.voice
    await message.bot.send_chat_action(chat_id=message.chat.id, action="typing")

    try:
        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        voice_file = await message.bot.get_file(voice.file_id)
        voice_bytes = await message.bot.download_file(voice_file.file_path)

        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è
        audio_file = io.BytesIO(voice_bytes.read())
        audio_file.name = "voice.ogg"

        transcribed_text = await openai_client.transcribe_audio(audio_file)

        if not transcribed_text:
            await message.answer(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.",
                reply_markup=get_end_keyboard()
            )
            return

        await message.answer(
            f"üé§ *–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:* {transcribed_text}",
            parse_mode='Markdown'
        )

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç ChatGPT
        response = await openai_client.get_chat_response(transcribed_text)

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ —Ä–µ—á—å
        audio_response = await openai_client.text_to_speech(response)

        if audio_response:
            await message.answer_voice(
                voice=io.BytesIO(audio_response),
                caption=f"ü§ñ *–û—Ç–≤–µ—Ç:* {response}",
                reply_markup=get_end_keyboard(),
                parse_mode='Markdown'
            )
        else:
            await message.answer(
                f"ü§ñ *–û—Ç–≤–µ—Ç:* {response}",
                reply_markup=get_end_keyboard(),
                parse_mode='Markdown'
            )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ handle_voice_message: {e}")
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.",
            reply_markup=get_end_keyboard()
        )


@router.message(VoiceStates.waiting_for_voice, F.text)
async def handle_voice_text_message(message: Message, state: FSMContext):
    user_message = message.text

    await message.bot.send_chat_action(chat_id=message.chat.id, action="typing")

    try:
        response = await openai_client.get_chat_response(user_message)

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ —Ä–µ—á—å
        audio_response = await openai_client.text_to_speech(response)

        if audio_response:
            await message.answer_voice(
                voice=io.BytesIO(audio_response),
                caption=f"ü§ñ *–û—Ç–≤–µ—Ç:* {response}",
                reply_markup=get_end_keyboard(),
                parse_mode='Markdown'
            )
        else:
            await message.answer(
                f"ü§ñ *–û—Ç–≤–µ—Ç:* {response}",
                reply_markup=get_end_keyboard(),
                parse_mode='Markdown'
            )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ handle_voice_text_message: {e}")
        await message.answer(
            "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è.",
            reply_markup=get_end_keyboard()
        )